{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (norm): StandardBatchNorm()\n",
      "  (relu): ReLU()\n",
      "  (layer1): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (nl1): StandardBatchNorm()\n",
      "      (nl2): StandardBatchNorm()\n",
      "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): StandardBatchNorm()\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (nl1): StandardBatchNorm()\n",
      "      (nl2): StandardBatchNorm()\n",
      "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (nl1): StandardBatchNorm()\n",
      "      (nl2): StandardBatchNorm()\n",
      "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): StandardBatchNorm()\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (nl1): StandardBatchNorm()\n",
      "      (nl2): StandardBatchNorm()\n",
      "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (nl1): StandardBatchNorm()\n",
      "      (nl2): StandardBatchNorm()\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): StandardBatchNorm()\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (nl1): StandardBatchNorm()\n",
      "      (nl2): StandardBatchNorm()\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(8, 8))\n",
      "  (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class StandardBatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True):\n",
    "        super(StandardBatchNorm, self).__init__()\n",
    "        self.momentum = momentum\n",
    "        self.running_mean = 0\n",
    "        self.running_var = 0\n",
    "        self.eps = torch.tensor(eps)\n",
    "        self.num_features = num_features\n",
    "        self.affine = affine\n",
    "        shape = (1, self.num_features, 1, 1)\n",
    "\n",
    "        if self.affine:\n",
    "            self.gamma = nn.Parameter(torch.empty(shape))\n",
    "            self.beta = nn.Parameter(torch.empty(shape))\n",
    "\n",
    "        self._param_init()\n",
    "\n",
    "    def _param_init(self):\n",
    "        nn.init.zeros_(self.beta)\n",
    "        nn.init.ones_(self.gamma)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            n = x.numel() / x.size(1)\n",
    "            dimensions = (0, 2, 3)\n",
    "            var = x.var(dim=dimensions, keepdim=True, unbiased=False)\n",
    "            mean = x.mean(dim=dimensions, keepdim=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = self.momentum * mean + (1 - self.momentum) * self.running_mean\n",
    "                self.running_var = self.momentum * (n / (n - 1)) * var + (1 - self.momentum) * self.running_var\n",
    "\n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "        dn = torch.sqrt(var + self.eps)\n",
    "        x = (x - mean) / dn\n",
    "        if self.affine:\n",
    "            x = x * self.gamma + self.beta\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, intermediate_channels, identity_downsample=None, stride=1, norm_type='batch'):\n",
    "        super().__init__()\n",
    "        self.expansion = 2\n",
    "        self.conv1 = nn.Conv2d(in_channels, intermediate_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "        if norm_type == 'bn':\n",
    "            self.nl1 = StandardBatchNorm(intermediate_channels)\n",
    "            self.nl2 = StandardBatchNorm(intermediate_channels * self.expansion)\n",
    "        # Add other normalization types here if needed\n",
    "\n",
    "        self.conv2 = nn.Conv2d(intermediate_channels, intermediate_channels * self.expansion, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.nl1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.nl2(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes, norm_type='bn'):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv1 = nn.Conv2d(image_channels, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        if norm_type == 'bn':\n",
    "            self.norm = StandardBatchNorm(16)\n",
    "            self.gamma = self.norm.gamma\n",
    "            self.beta = self.norm.beta\n",
    "        # Add other normalization types here if needed\n",
    "        else:\n",
    "            raise ValueError(\"Invalid normalization type. Choose from 'bn'.\")\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.layer1 = self._make_layer(block, layers[0], intermediate_channels=16, stride=1, norm_type=norm_type)\n",
    "        self.layer2 = self._make_layer(block, layers[1], intermediate_channels=32, stride=2, norm_type=norm_type)\n",
    "        self.layer3 = self._make_layer(block, layers[2], intermediate_channels=64, stride=2, norm_type=norm_type)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((8, 8))\n",
    "        self.fc = nn.Linear(128 * 8 * 8, num_classes)  # Adjusted this line\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)  # Adjusted this line\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride, norm_type):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 2:\n",
    "            if norm_type == 'bn':\n",
    "                identity_downsample = nn.Sequential(\n",
    "                    nn.Conv2d(self.in_channels, intermediate_channels * 2, kernel_size=1, stride=stride, bias=False),\n",
    "                    StandardBatchNorm(intermediate_channels * 2)\n",
    "                )\n",
    "            # Add other normalization types here if needed\n",
    "            else:\n",
    "                raise ValueError(\"Invalid normalization type. Choose from 'bn'.\")\n",
    "\n",
    "        layers.append(block(self.in_channels, intermediate_channels, identity_downsample, stride, norm_type))\n",
    "        self.in_channels = intermediate_channels * 2\n",
    "\n",
    "        for _ in range(1, num_residual_blocks):  # Adjusted this line\n",
    "            layers.append(block(self.in_channels, intermediate_channels, norm_type=norm_type))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "resnet = ResNet(Block, [2, 2, 2], image_channels=3, num_classes=10, norm_type='bn')\n",
    "print(resnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: gamma, Shape: torch.Size([1, 16, 1, 1])\n",
      "Parameter name: beta, Shape: torch.Size([1, 16, 1, 1])\n",
      "Parameter name: conv1.weight, Shape: torch.Size([16, 3, 3, 3])\n",
      "Parameter name: layer1.0.conv1.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: layer1.0.nl1.gamma, Shape: torch.Size([1, 16, 1, 1])\n",
      "Parameter name: layer1.0.nl1.beta, Shape: torch.Size([1, 16, 1, 1])\n",
      "Parameter name: layer1.0.nl2.gamma, Shape: torch.Size([1, 32, 1, 1])\n",
      "Parameter name: layer1.0.nl2.beta, Shape: torch.Size([1, 32, 1, 1])\n",
      "Parameter name: layer1.0.conv2.weight, Shape: torch.Size([32, 16, 3, 3])\n",
      "Parameter name: layer1.0.identity_downsample.0.weight, Shape: torch.Size([32, 16, 1, 1])\n",
      "Parameter name: layer1.0.identity_downsample.1.gamma, Shape: torch.Size([1, 32, 1, 1])\n",
      "Parameter name: layer1.0.identity_downsample.1.beta, Shape: torch.Size([1, 32, 1, 1])\n",
      "Parameter name: layer1.1.conv1.weight, Shape: torch.Size([16, 32, 3, 3])\n",
      "Parameter name: layer1.1.nl1.gamma, Shape: torch.Size([1, 16, 1, 1])\n",
      "Parameter name: layer1.1.nl1.beta, Shape: torch.Size([1, 16, 1, 1])\n",
      "Parameter name: layer1.1.nl2.gamma, Shape: torch.Size([1, 32, 1, 1])\n",
      "Parameter name: layer1.1.nl2.beta, Shape: torch.Size([1, 32, 1, 1])\n",
      "Parameter name: layer1.1.conv2.weight, Shape: torch.Size([32, 16, 3, 3])\n",
      "Parameter name: layer2.0.conv1.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: layer2.0.nl1.gamma, Shape: torch.Size([1, 32, 1, 1])\n",
      "Parameter name: layer2.0.nl1.beta, Shape: torch.Size([1, 32, 1, 1])\n",
      "Parameter name: layer2.0.nl2.gamma, Shape: torch.Size([1, 64, 1, 1])\n",
      "Parameter name: layer2.0.nl2.beta, Shape: torch.Size([1, 64, 1, 1])\n",
      "Parameter name: layer2.0.conv2.weight, Shape: torch.Size([64, 32, 3, 3])\n",
      "Parameter name: layer2.0.identity_downsample.0.weight, Shape: torch.Size([64, 32, 1, 1])\n",
      "Parameter name: layer2.0.identity_downsample.1.gamma, Shape: torch.Size([1, 64, 1, 1])\n",
      "Parameter name: layer2.0.identity_downsample.1.beta, Shape: torch.Size([1, 64, 1, 1])\n",
      "Parameter name: layer2.1.conv1.weight, Shape: torch.Size([32, 64, 3, 3])\n",
      "Parameter name: layer2.1.nl1.gamma, Shape: torch.Size([1, 32, 1, 1])\n",
      "Parameter name: layer2.1.nl1.beta, Shape: torch.Size([1, 32, 1, 1])\n",
      "Parameter name: layer2.1.nl2.gamma, Shape: torch.Size([1, 64, 1, 1])\n",
      "Parameter name: layer2.1.nl2.beta, Shape: torch.Size([1, 64, 1, 1])\n",
      "Parameter name: layer2.1.conv2.weight, Shape: torch.Size([64, 32, 3, 3])\n",
      "Parameter name: layer3.0.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Parameter name: layer3.0.nl1.gamma, Shape: torch.Size([1, 64, 1, 1])\n",
      "Parameter name: layer3.0.nl1.beta, Shape: torch.Size([1, 64, 1, 1])\n",
      "Parameter name: layer3.0.nl2.gamma, Shape: torch.Size([1, 128, 1, 1])\n",
      "Parameter name: layer3.0.nl2.beta, Shape: torch.Size([1, 128, 1, 1])\n",
      "Parameter name: layer3.0.conv2.weight, Shape: torch.Size([128, 64, 3, 3])\n",
      "Parameter name: layer3.0.identity_downsample.0.weight, Shape: torch.Size([128, 64, 1, 1])\n",
      "Parameter name: layer3.0.identity_downsample.1.gamma, Shape: torch.Size([1, 128, 1, 1])\n",
      "Parameter name: layer3.0.identity_downsample.1.beta, Shape: torch.Size([1, 128, 1, 1])\n",
      "Parameter name: layer3.1.conv1.weight, Shape: torch.Size([64, 128, 3, 3])\n",
      "Parameter name: layer3.1.nl1.gamma, Shape: torch.Size([1, 64, 1, 1])\n",
      "Parameter name: layer3.1.nl1.beta, Shape: torch.Size([1, 64, 1, 1])\n",
      "Parameter name: layer3.1.nl2.gamma, Shape: torch.Size([1, 128, 1, 1])\n",
      "Parameter name: layer3.1.nl2.beta, Shape: torch.Size([1, 128, 1, 1])\n",
      "Parameter name: layer3.1.conv2.weight, Shape: torch.Size([128, 64, 3, 3])\n",
      "Parameter name: fc.weight, Shape: torch.Size([10, 8192])\n",
      "Parameter name: fc.bias, Shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Print all parameters\n",
    "for name, param in resnet.named_parameters():\n",
    "    print(f\"Parameter name: {name}, Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(),'resent.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(Block, [2, 2, 2], image_channels=3, num_classes=10, norm_type='bn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('resent.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
